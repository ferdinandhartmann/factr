import torch
import numpy as np
import cv2
from pathlib import Path
import matplotlib.pyplot as plt
from tqdm import tqdm
import yaml
import pickle
from collections import deque
import sys
import warnings
import argparse

# Hydra/OmegaConf é–¢é€£
from omegaconf import OmegaConf
from hydra.utils import instantiate

# å…ˆã«ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ resolver ã‚’ç™»éŒ²ã•ã›ã‚‹
try:
    import factr.misc
except ImportError:
    pass

# ==========================================
# è­¦å‘Šãƒ»ã‚¤ãƒ³ãƒãƒ¼ãƒˆé–¢é€£
# ==========================================
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå´ã§ã® register_new_resolver ã¯å‰Šé™¤ã—ã¾ã—ãŸï¼ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªå´ã¨ç«¶åˆã™ã‚‹ãŸã‚ï¼‰

# ==================================================================================
# 1. PARAMETERS & PATHS
# ==================================================================================
parser = argparse.ArgumentParser()
parser.add_argument("--model_name", type=str, required=True, help="Baseline model folder")
parser.add_argument("--ckpt_name", type=str, default="ckpt_020000")
args = parser.parse_args()

DEVICE = "cuda:0" if torch.cuda.is_available() else "cpu"
NUM_SAMPLES = 10
IMG_CHUNK = 1
PROJECT_ROOT = Path(__file__).resolve().parent.parent
CHECKPOINTS_DIR = PROJECT_ROOT / "checkpoints"
ROLLOUT_CFG_PATH = PROJECT_ROOT / "process_data/processed_data/1217_mix/rollout_config.yaml"

SAVE_DIR = Path("/home/otake/FACTR-pr/FACTR-project/result_output/base_vs_mine")
SAVE_DIR.mkdir(parents=True, exist_ok=True)

eval_targets = [
    (Path("/data/otake/box_lift_up_side/20251218_stiff/eval"), [f"ep_{i:02d}" for i in range(55, 60)]),
    (Path("/data/otake/box_lift_up_side/20251217_soft/eval"), [f"ep_{i:02d}" for i in range(55, 60)]),
]


# ==================================================================================
# 2. è£œåŠ©é–¢æ•°
# ==================================================================================
def load_policy(model_name, ckpt_name, device):
    model_dir = CHECKPOINTS_DIR / model_name
    exp_cfg_path = model_dir / "rollout/exp_config.yaml"
    ckpt_path = model_dir / f"{ckpt_name}.ckpt"

    if not ckpt_path.exists():
        raise FileNotFoundError(f"Checkpoint not found: {ckpt_path}")

    # 1. Configã‚’ãƒ­ãƒ¼ãƒ‰
    cfg = OmegaConf.load(exp_cfg_path)

    # 2. Hydra å›ºæœ‰ã®ä¸è¦ãªã‚­ãƒ¼ã‚’å‰Šé™¤
    if "hydra" in cfg:
        cfg.pop("hydra", None)

    # ã€é‡è¦ã€‘OmegaConf.resolve(cfg) ã¯å‰Šé™¤ã—ã¾ã™
    # ä»£ã‚ã‚Šã«ã€å€‹åˆ¥ã®ãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–å€¤ï¼ˆãƒ‘ã‚¹ã‚„æ•°å€¤ï¼‰ã ã‘ãŒå¿…è¦ãªå ´åˆã¯å€‹åˆ¥ã« resolve ã—ã¾ã™ãŒã€
    # åŸºæœ¬çš„ã«ã¯ instantiate ã«ä»»ã›ã‚‹ã®ãŒæ­£è§£ã§ã™ã€‚

    if "task" in cfg and "cam_indexes" in cfg.task:
        cfg.task.n_cams = len(cfg.task.cam_indexes)

    # agent ã®è¨­å®šã‚’ä¸€éƒ¨æ›¸ãæ›ãˆã‚‹
    cfg.agent.sanity_check_posterior = False

    print(f"Instantiating policy for {model_name}...")

    # 3. instantiate ã‚’å®Ÿè¡Œï¼ˆã“ã“ã§å†…éƒ¨çš„ã«ãƒªã‚¾ãƒ«ãƒ–ã•ã‚Œã¾ã™ï¼‰
    policy = instantiate(cfg.agent)
    policy.to(device)

    # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ãƒ­ãƒ¼ãƒ‰
    ckpt = torch.load(ckpt_path, map_location=device)
    state_dict = {k.replace("module.", ""): v for k, v in ckpt["model"].items()}
    missing_keys, unexpected_keys = policy.load_state_dict(state_dict, strict=False)

    # # é‡ã¿ãŒæ­£ã—ããƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯
    # if len(missing_keys) > 0:
    #     print(f"âš ï¸ [WARNING] {model_name} ã®é‡ã¿ãŒ {len(missing_keys)} å€‹ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼")
    #     print(f"   ä¾‹: {missing_keys[:3]}") # æœ€åˆã®3å€‹ã ã‘è¡¨ç¤º
    # else:
    #     print(f"âœ… {model_name} ã®é‡ã¿ãŒã™ã¹ã¦æ­£å¸¸ã«ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸï¼")

    policy.load_state_dict(state_dict, strict=False)
    policy.eval()
    return policy


def load_and_extract_raw_data(pkl_path: Path):
    with open(pkl_path, "rb") as f:
        raw_data = pickle.load(f)

    image_obs, torque_obs, actions = [], [], []
    if "data" not in raw_data:
        return [], [], []

    entries = raw_data["data"]
    image_topic = "/realsense/front/im"
    obs_topic = "/franka_robot_state_broadcaster/external_joint_torques"
    possible_topics = [
        "/joint_impedance_dynamic_gain_controller/joint_impedance_command",
        "/joint_impedance_command_controller/joint_trajectory",
    ]

    action_topic = next((t for t in possible_topics if t in entries), None)
    if action_topic is None:
        return [], [], []

    for v in entries[action_topic]:
        if isinstance(v, dict) and "position" in v:
            actions.append(v["position"])

    if not actions:
        return [], [], []

    if image_topic in entries:
        for v in entries[image_topic]:
            if isinstance(v, dict) and "data" in v:
                try:
                    if isinstance(v["data"], bytes):
                        nparr = np.frombuffer(v["data"], np.uint8)
                        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                    else:
                        img = np.frombuffer(v["data"], dtype=np.uint8).reshape((v["height"], v["width"], -1))
                    image_obs.append(img)
                except:
                    pass

    if obs_topic in entries:
        for v in entries[obs_topic]:
            if isinstance(v, dict) and "effort" in v:
                torque_obs.append(v["effort"])

    torque_obs, actions = np.array(torque_obs), np.array(actions)
    N = min(len(image_obs), len(torque_obs), len(actions))
    return image_obs[:N], torque_obs[:N], actions[:N]


def preprocess_image(img, device):
    if img.ndim == 2:
        img = np.repeat(img[..., None], 3, axis=-1)
    img = cv2.resize(img, (224, 224))
    img_tensor = torch.from_numpy(img).float().permute(2, 0, 1)[None] / 255.0
    mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)
    std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)
    return ((img_tensor - mean) / std).to(device)


# ==================================================================================
# 3. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ==================================================================================
policy = load_policy(args.model_name, args.ckpt_name, DEVICE)

with open(ROLLOUT_CFG_PATH, "r") as f:
    rollout_config = yaml.safe_load(f)

obs_mean = torch.tensor(rollout_config["norm_stats"]["state"]["mean"]).float().to(DEVICE)
obs_std = torch.tensor(rollout_config["norm_stats"]["state"]["std"]).float().to(DEVICE)

all_uncertainties = []  # 10ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰åˆ†ã‚’æ ¼ç´

print(f"Starting Uncertainty Evaluation (Samples: {NUM_SAMPLES})...")

for target_dir, episodes in eval_targets:
    for ep_name in episodes:
        pkl_path = target_dir / f"{ep_name}.pkl"
        if not pkl_path.exists():
            continue

        image_obs, torque_obs, _ = load_and_extract_raw_data(pkl_path)
        if not image_obs:
            continue

        ep_unc = []
        image_history = deque(maxlen=IMG_CHUNK)

        for i in tqdm(range(len(image_obs)), desc=f"Eval {ep_name}", leave=False):
            img_tensor = preprocess_image(image_obs[i], DEVICE)
            if len(image_history) == 0:
                for _ in range(IMG_CHUNK):
                    image_history.append(img_tensor)
            else:
                image_history.append(img_tensor)

            input_img = {"cam0": torch.cat(list(image_history), dim=1)}
            torque_norm = (torch.from_numpy(torque_obs[i]).float().to(DEVICE) - obs_mean) / obs_std
            torque_norm = torque_norm.unsqueeze(0)

            with torch.no_grad():
                # get_uncertainty_entropy ã‚’ä½¿ç”¨
                # åŠ é‡å¹³å‡ã‚’æœ‰åŠ¹ã«ã™ã‚‹è¨­å®š (unc_weighted=True)
                _, uncertainty = policy.get_uncertainty_entropy(
                    input_img,
                    torque_norm,
                    sample=True,
                    num_samples=NUM_SAMPLES,
                    unc_step_mode=False,
                    unc_weighted=True,
                    w_start=0.1,
                    w_end=0.9,
                )

            # uncertaintyã®å½¢çŠ¶ã¯ (B, 1, Dim) ãªã®ã§ã€å…¨æ¬¡å…ƒã®å¹³å‡ã‚’ã¨ã£ã¦ã‚¹ã‚«ãƒ©ãƒ¼ã«ã™ã‚‹
            ep_unc.append(uncertainty.mean().cpu().item())

        all_uncertainties.append(ep_unc)


# ==================================================================================
# 4. çµ±è¨ˆè¨ˆç®— & ãƒ—ãƒ­ãƒƒãƒˆ (å¡—ã‚Šã¤ã¶ã—ãªã—ãƒ»å€‹åˆ¥ç·šã¨å¹³å‡ã®ã¿)
# ==================================================================================
def get_padded_mean(unc_list):
    # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã”ã¨ã®é•·ã•ãŒç•°ãªã‚‹ãŸã‚ã€æœ€å¤§é•·ã«åˆã‚ã›ã¦ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
    maxlen = max(len(x) for x in unc_list)
    arr = np.full((len(unc_list), maxlen), np.nan)
    for i, x in enumerate(unc_list):
        arr[i, : len(x)] = x
    # æ™‚é–“è»¸ã”ã¨ã®å¹³å‡ã‚’è¨ˆç®—ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒãªã„éƒ¨åˆ†ã¯ç„¡è¦–ï¼‰
    return np.nanmean(arr, axis=0)


mean_unc = get_padded_mean(all_uncertainties)

# --- æ•°å€¤å‡ºåŠ› ---
max_val = np.nanmax(mean_unc)
min_val = np.nanmin(mean_unc)
print("-" * 40)
print(f"ğŸ“Š Uncertainty Analysis Results (10 episodes)")
print(f"   Mean Uncertainty MAX: {max_val:.6f}")
print(f"   Mean Uncertainty MIN: {min_val:.6f}")
print("-" * 40)

# --- ã‚°ãƒ©ãƒ•ä½œæˆ ---
plt.figure(figsize=(12, 7))

# 1. å„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®ãƒ—ãƒ­ãƒƒãƒˆ (ç´°ã„ç·š - å€‹åˆ¥ã®åˆ†æ•£ã®æ¨ç§»)
for i, u in enumerate(all_uncertainties):
    label = "Individual Episode Variance" if i == 0 else None
    plt.plot(u, color="blue", alpha=0.2, linewidth=0.8, label=label)

# 2. å…¨ä½“ã®å¹³å‡ãƒ—ãƒ­ãƒƒãƒˆ (å¤ªã„å®Ÿç·š)
plt.plot(mean_unc, color="blue", linewidth=2.5, label="Mean of Variances")

# ã‚°ãƒ©ãƒ•ã®è£…é£¾
plt.title(f"Action Uncertainty (Weighted Variance) - {args.model_name}", fontsize=14)
plt.xlabel("Timestep", fontsize=12)
plt.ylabel("Uncertainty Value", fontsize=12)
plt.legend(loc="upper right", frameon=True)
plt.grid(True, linestyle=":", alpha=0.6)

# ä¿å­˜
save_path = SAVE_DIR / f"unc_plot_{args.model_name}.png"
plt.savefig(save_path, dpi=200, bbox_inches="tight")
plt.show()

print(f"ğŸ“Š Plot saved to: {save_path}")
