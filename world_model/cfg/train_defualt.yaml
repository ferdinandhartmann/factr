# @package _global_

hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}

data:
  buffer_path: /home/ferdinand/activeinference/factr/process_data/training_data/fourgoals_1_newnorm_train/buf.pkl
  stats_path: /home/ferdinand/activeinference/factr/process_data/training_data/fourgoals_1_newnorm_train/rollout_config.yaml
  # seq_len here is the number of actions returned. Observations are seq_len + 1.
  seq_len: 30 # future prediction length
  obs_keys:
    - state
  include_goals: false
  normalize_obs: false
  normalize_action: false

logging:
  enabled: true
  project: world-model-test
  entity: null
  tags: []
  log_every: 100
  name: rssm_newnorm_train_13


model:
  stoch_dim: 64    # uncertainty / extra information channel, CHECK!
  deter_dim: 128   # memory size
  hidden_dim: 128  # MLP width
  obs_window: 1 # just for training, how many previous obs to give the encoder
  # Smaller than the common Dreamer image-default; low-dim state transitions are often nearly deterministic.
  min_std: 0.05

  # For low-dimensional state observations, start WITHOUT a VAE.
  use_vae: true
  vae_latent_dim: 20   # how much information the VAE can carry, dimension of the observation latent x_t.
  vae_hidden_dim: 64  # Width of the MLP inside the VAE.
  vae_min_std: 0.05    # minimum observation noise


train:
  seed: 7
  # Number of optimizer updates. Prefer this over "epochs" because dataset size can vary a lot.
  max_steps: 8000
  batch_size: 64
  lr: 0.0003
  
  # For state-only buffers, start with a small KL weight to prevent the model from ignoring reconstruction.
  kl_weight: 0.6
  kl_warmup_steps: 800 # Helps prevent the KL term from dominating early training so recon learns first
  kl_balance: true     # Dreamer-style KL balancing often improves stability.
  kl_balance_scale: 0.5
  rssm_sample: true   # Low-dim states often train better with deterministic posterior latents: use false
  free_nats: 0.3
  grad_clip: 80.0

  # vae_recon_weight: 1.0
  # vae_kl_weight: 0.02
  # vae_kl_warmup_steps: 800
  print_every: 100
  print_updates: true

  device: cuda
  num_workers: 10
  pin_memory: true

  # Save checkpoint settings
  save_every: 1000
  keep_last: 1


